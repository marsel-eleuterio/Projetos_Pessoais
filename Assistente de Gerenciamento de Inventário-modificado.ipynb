{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistente de Gerenciamento de Inventário\" usando o LangGraph.\n",
    "##  O script irá monitorar os níveis de inventário, prever faltas de estoque usando dados históricos e tendências, e automatizar processos de reabastecimento, enviando alertas ou fazendo pedidos quando necessário.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 1: Instalação de Bibliotecas Necessárias\n",
    "Primeiramente, precisamos instalar as bibliotecas que serão utilizadas no script. Execute a célula abaixo no seu Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting duckdb\n",
      "  Downloading duckdb-1.3.2-cp313-cp313-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: langgraph in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (0.3.69)\n",
      "Requirement already satisfied: openai in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (1.93.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (1.1.1)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langgraph) (0.1.73)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langchain-core) (0.4.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langchain-core) (4.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langsmith>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from langsmith>=0.3.45->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\marse\\documentos\\scoras\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading duckdb-1.3.2-cp313-cp313-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.4 MB 7.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/11.4 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/11.4 MB 5.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.4 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.4 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.3/11.4 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, duckdb\n",
      "\n",
      "   -------------------- ------------------- 1/2 [duckdb]\n",
      "   -------------------- ------------------- 1/2 [duckdb]\n",
      "   -------------------- ------------------- 1/2 [duckdb]\n",
      "   ---------------------------------------- 2/2 [duckdb]\n",
      "\n",
      "Successfully installed duckdb-1.3.2 graphviz-0.21\n"
     ]
    }
   ],
   "source": [
    "!pip install duckdb pandas matplotlib seaborn langgraph langchain-openai langchain-core openai python-dotenv graphviz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 2: Importações e Configurações Iniciais\n",
    "\n",
    "Nesta parte, importamos as bibliotecas necessárias e configuramos o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import os\n",
    "import duckdb  # Banco de dados embutido\n",
    "import pandas as pd  # Manipulação de dados\n",
    "import numpy as np  # Operações numéricas\n",
    "import matplotlib.pyplot as plt  # Visualizações\n",
    "import seaborn as sns  # Visualizações aprimoradas\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "from langgraph.graph import StateGraph, START, END  # Para criar o fluxo de trabalho\n",
    "from langchain_openai.chat_models import ChatOpenAI  # Modelo de linguagem\n",
    "from langchain_core.prompts import ChatPromptTemplate  # Para criar prompts personalizados\n",
    "from dotenv import load_dotenv  # Para carregar variáveis de ambiente\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 3: Criação de um Banco de Dados Fictício com DuckDB\n",
    "Vamos criar um banco de dados fictício que representa o inventário e histórico de vendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x20bfcff46b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conectar ao banco de dados em memória\n",
    "conn = duckdb.connect(database=':memory:')\n",
    "\n",
    "# Criar dados fictícios de inventário\n",
    "inventory_data = pd.DataFrame({\n",
    "    'product_id': [f'P{str(i).zfill(3)}' for i in range(1, 21)],\n",
    "    'product_name': [f'Produto {i}' for i in range(1, 21)],\n",
    "    'current_stock': np.random.randint(0, 100, size=20),\n",
    "    'reorder_level': np.random.randint(10, 50, size=20),\n",
    "    'lead_time_days': np.random.randint(1, 15, size=20)\n",
    "})\n",
    "\n",
    "# Criar dados fictícios de vendas históricas\n",
    "date_range = pd.date_range(end=pd.Timestamp.today(), periods=180)\n",
    "sales_history = pd.DataFrame({\n",
    "    'date': np.random.choice(date_range, size=500),\n",
    "    'product_id': np.random.choice(inventory_data['product_id'], size=500),\n",
    "    'quantity_sold': np.random.randint(1, 10, size=500)\n",
    "})\n",
    "\n",
    "# Inserir os dados no DuckDB\n",
    "conn.execute(\"CREATE TABLE inventory AS SELECT * FROM inventory_data\")\n",
    "conn.execute(\"CREATE TABLE sales_history AS SELECT * FROM sales_history\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id product_name  current_stock  reorder_level  lead_time_days\n",
      "0        P001    Produto 1              4             24               2\n",
      "1        P002    Produto 2             39             13               1\n",
      "2        P003    Produto 3             24             10               6\n",
      "3        P004    Produto 4             79             44              11\n",
      "4        P005    Produto 5              3             11               4\n",
      "5        P006    Produto 6             47             10               9\n",
      "6        P007    Produto 7             86             16              14\n",
      "7        P008    Produto 8             32             43               6\n",
      "8        P009    Produto 9             91             32               5\n",
      "9        P010   Produto 10             47             42               4\n",
      "10       P011   Produto 11             40             35               6\n",
      "11       P012   Produto 12             60             38              10\n",
      "12       P013   Produto 13             17             48              14\n",
      "13       P014   Produto 14             38             20              10\n",
      "14       P015   Produto 15             96             18               7\n",
      "15       P016   Produto 16             92             11               4\n",
      "16       P017   Produto 17             44             13               3\n",
      "17       P018   Produto 18             32             19               8\n",
      "18       P019   Produto 19             91             24              11\n",
      "19       P020   Produto 20             29             18               6\n",
      "                          date product_id  quantity_sold\n",
      "0   2025-03-03 16:47:07.514100       P011              5\n",
      "1   2025-04-05 16:47:07.514100       P009              6\n",
      "2   2025-05-30 16:47:07.514100       P008              1\n",
      "3   2025-06-22 16:47:07.514100       P005              7\n",
      "4   2025-05-29 16:47:07.514100       P007              5\n",
      "..                         ...        ...            ...\n",
      "495 2025-03-07 16:47:07.514100       P017              6\n",
      "496 2025-02-14 16:47:07.514100       P001              9\n",
      "497 2025-07-24 16:47:07.514100       P012              1\n",
      "498 2025-02-16 16:47:07.514100       P012              6\n",
      "499 2025-06-19 16:47:07.514100       P001              6\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#testando o banco de dados\n",
    "print(conn.execute(\"SELECT * FROM inventory\").df())\n",
    "print(conn.execute(\"SELECT * FROM sales_history\").df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 4: Definição das Estruturas de Dados e Estado\n",
    "\n",
    "Definimos as estruturas de dados que serão usadas no fluxo de trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrutura do estado\n",
    "class State(TypedDict):\n",
    "    low_stock_products: pd.DataFrame\n",
    "    demand_forecast: pd.DataFrame\n",
    "    replenishment_orders: pd.DataFrame\n",
    "    alerts: List[str]\n",
    "    errors: List[str]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 5: Implementação das Funções de Fluxo de Trabalho\n",
    "\n",
    "5.1. Função para Identificar Produtos com Baixo Estoque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inventory_levels(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Verifica o nível atual de estoque e identifica produtos abaixo do nível de reabastecimento.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Consultar o banco de dados para obter o inventário atual\n",
    "        inventory = conn.execute(\"SELECT * FROM inventory\").df()\n",
    "        \n",
    "        # Identificar produtos com estoque abaixo do nível de reabastecimento\n",
    "        low_stock = inventory[inventory['current_stock'] <= inventory['reorder_level']]\n",
    "        \n",
    "        # Atualizar o estado\n",
    "        state['low_stock_products'] = low_stock\n",
    "    except Exception as e:\n",
    "        state['errors'].append(f\"Erro ao verificar os níveis de inventário: {e}\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2. Função para Prever a Demanda Futura\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_demand(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Prevê a demanda futura com base no histórico de vendas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obter produtos com baixo estoque\n",
    "        low_stock = state.get('low_stock_products')\n",
    "        \n",
    "        if low_stock is None or low_stock.empty:\n",
    "            state['errors'].append(\"Nenhum produto com baixo estoque para prever demanda.\")\n",
    "            return state\n",
    "        \n",
    "        # Obter histórico de vendas\n",
    "        sales = conn.execute(\"SELECT * FROM sales_history\").df()\n",
    "        \n",
    "        # Combinar dados\n",
    "        data = sales.merge(low_stock[['product_id']], on='product_id')\n",
    "        \n",
    "        # Prever demanda (neste exemplo simples, usaremos a média diária)\n",
    "        forecast = data.groupby('product_id').agg({\n",
    "            'quantity_sold': lambda x: x.sum() / 180  # Média diária nos últimos 180 dias\n",
    "        }).reset_index()\n",
    "        forecast.rename(columns={'quantity_sold': 'daily_average_sold'}, inplace=True)\n",
    "        \n",
    "        # Atualizar o estado\n",
    "        state['demand_forecast'] = forecast\n",
    "    except Exception as e:\n",
    "        state['errors'].append(f\"Erro ao prever a demanda: {e}\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3. Função para Gerar Ordens de Reabastecimento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_replenishment_orders(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Gera ordens de reabastecimento com base na previsão de demanda e tempo de entrega.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        low_stock = state.get('low_stock_products')\n",
    "        forecast = state.get('demand_forecast')\n",
    "        \n",
    "        if low_stock is None or low_stock.empty or forecast is None or forecast.empty:\n",
    "            state['errors'].append(\"Dados insuficientes para gerar ordens de reabastecimento.\")\n",
    "            return state\n",
    "        \n",
    "        # Combinar dados\n",
    "        orders = low_stock.merge(forecast, on='product_id')\n",
    "        \n",
    "        # Calcular a quantidade necessária\n",
    "        orders['replenishment_quantity'] = (\n",
    "            orders['daily_average_sold'] * orders['lead_time_days']\n",
    "        ).astype(int) - orders['current_stock']\n",
    "        \n",
    "        # Filtrar pedidos com quantidade positiva\n",
    "        orders = orders[orders['replenishment_quantity'] > 0]\n",
    "        \n",
    "        # Atualizar o estado\n",
    "        state['replenishment_orders'] = orders[['product_id', 'product_name', 'replenishment_quantity']]\n",
    "    except Exception as e:\n",
    "        state['errors'].append(f\"Erro ao gerar ordens de reabastecimento: {e}\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4. Função para Enviar Alertas ou Fazer Pedidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_alerts_or_place_orders(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Envia alertas ou faz pedidos de reabastecimento.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        orders = state.get('replenishment_orders')\n",
    "        \n",
    "        if orders is None or orders.empty:\n",
    "            state['alerts'].append(\"Nenhum produto necessita de reabastecimento imediato.\")\n",
    "            return state\n",
    "        \n",
    "        # Exemplo: Enviar um alerta para cada produto\n",
    "        for _, row in orders.iterrows():\n",
    "            alert = f\"Produto {row['product_name']} (ID: {row['product_id']}) precisa ser reabastecido. Quantidade sugerida: {row['replenishment_quantity']} unidades.\"\n",
    "            state['alerts'].append(alert)\n",
    "            # Aqui, você poderia integrar com um sistema de pedidos automático\n",
    "    except Exception as e:\n",
    "        state['errors'].append(f\"Erro ao enviar alertas ou fazer pedidos: {e}\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 6: Construção do Fluxo de Trabalho com LangGraph\n",
    "\n",
    "Vamos agora definir o fluxo de trabalho usando o LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o grafo de estado\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Adicionar nós\n",
    "workflow.add_node(\"check_inventory_levels\", check_inventory_levels)\n",
    "workflow.add_node(\"forecast_demand\", forecast_demand)\n",
    "workflow.add_node(\"generate_replenishment_orders\", generate_replenishment_orders)\n",
    "workflow.add_node(\"send_alerts_or_place_orders\", send_alerts_or_place_orders)\n",
    "\n",
    "# Definir as arestas\n",
    "workflow.add_edge(START, \"check_inventory_levels\")\n",
    "workflow.add_edge(\"check_inventory_levels\", \"forecast_demand\")\n",
    "workflow.add_edge(\"forecast_demand\", \"generate_replenishment_orders\")\n",
    "workflow.add_edge(\"generate_replenishment_orders\", \"send_alerts_or_place_orders\")\n",
    "workflow.add_edge(\"send_alerts_or_place_orders\", END)\n",
    "\n",
    "# Definir o ponto de entrada\n",
    "workflow.set_entry_point(\"check_inventory_levels\")\n",
    "\n",
    "# Compilar o grafo\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__firstlineno__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_add_schema', '_all_edges', 'add_conditional_edges', 'add_edge', 'add_node', 'add_sequence', 'branches', 'channels', 'compile', 'compiled', 'config_schema', 'edges', 'input_schema', 'managed', 'nodes', 'output_schema', 'schemas', 'set_conditional_entry_point', 'set_entry_point', 'set_finish_point', 'state_schema', 'validate', 'waiting_edges']\n"
     ]
    }
   ],
   "source": [
    "print(dir(workflow))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 87 Função Principal para Executar o Fluxo de Trabalho\n",
    "\n",
    "Definimos uma função principal para executar o fluxo de trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_inventory():\n",
    "    \"\"\"\n",
    "    Executa o fluxo de gerenciamento de inventário.\n",
    "    \n",
    "    Returns:\n",
    "        State: Estado final após o processamento.\n",
    "    \"\"\"\n",
    "    initial_state = State(\n",
    "        low_stock_products=None,\n",
    "        demand_forecast=None,\n",
    "        replenishment_orders=None,\n",
    "        alerts=[],\n",
    "        errors=[]\n",
    "    )\n",
    "    final_state = app.invoke(initial_state)\n",
    "    return final_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 8: Executando o Script e Verificando os Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar o gerenciamento de inventário\n",
    "final_state = manage_inventory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alertas:\n",
      "- Nenhum produto necessita de reabastecimento imediato.\n"
     ]
    }
   ],
   "source": [
    "# Verificar se houve erros\n",
    "if final_state['errors']:\n",
    "    print(\"Erros encontrados:\")\n",
    "    for error in final_state['errors']:\n",
    "        print(f\"- {error}\")\n",
    "else:\n",
    "    # Exibir alertas\n",
    "    if final_state['alerts']:\n",
    "        print(\"Alertas:\")\n",
    "        for alert in final_state['alerts']:\n",
    "            print(f\"- {alert}\")\n",
    "    else:\n",
    "        print(\"Nenhum alerta a ser exibido.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise do Código de Gerenciamento de Inventário com LangGraph\n",
    "\n",
    "## Conceitos Principais do LangGraph Utilizados\n",
    "\n",
    "* **StateGraph**: \n",
    "  - Classe central do LangGraph que permite criar fluxos de trabalho baseados em estado\n",
    "  - Gerencia a transição entre diferentes nós do grafo\n",
    "  - Mantém o estado consistente durante toda a execução\n",
    "\n",
    "* **State (TypedDict)**:\n",
    "  - Estrutura de dados fortemente tipada que define o estado do workflow\n",
    "  - Permite rastrear múltiplos aspectos do processo (inventário, previsões, alertas, etc.)\n",
    "\n",
    "* **Nós do Grafo**:\n",
    "  - Cada função representa um nó no grafo de workflow\n",
    "  - Os nós processam e modificam o estado de forma sequencial\n",
    "  - Retornam sempre um novo estado atualizado\n",
    "\n",
    "* **START/END**:\n",
    "  - Marcadores especiais do LangGraph que definem início e fim do workflow\n",
    "  - Permitem estruturar o fluxo de execução de forma clara\n",
    "\n",
    "## Análise do Código por Seções\n",
    "\n",
    "### 1. Configuração Inicial\n",
    "```python\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "```\n",
    "- Importa componentes essenciais do LangGraph\n",
    "- Configura ambiente e dependências\n",
    "\n",
    "### 2. Estrutura de Dados\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    low_stock_products: pd.DataFrame\n",
    "    demand_forecast: pd.DataFrame\n",
    "    replenishment_orders: pd.DataFrame\n",
    "    alerts: List[str]\n",
    "    errors: List[str]\n",
    "```\n",
    "- Define estrutura do estado usando TypedDict\n",
    "- Cada campo representa um aspecto específico do processo\n",
    "\n",
    "### 3. Funções de Processamento\n",
    "```python\n",
    "def check_inventory_levels(state: State) -> State:\n",
    "    # ...\n",
    "def forecast_demand(state: State) -> State:\n",
    "    # ...\n",
    "def generate_replenishment_orders(state: State) -> State:\n",
    "    # ...\n",
    "def send_alerts_or_place_orders(state: State) -> State:\n",
    "    # ...\n",
    "```\n",
    "- Cada função é um nó do grafo\n",
    "- Recebem e retornam o estado\n",
    "- Seguem padrão de imutabilidade\n",
    "\n",
    "### 4. Construção do Workflow\n",
    "```python\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"check_inventory_levels\", check_inventory_levels)\n",
    "# ...\n",
    "workflow.add_edge(START, \"check_inventory_levels\")\n",
    "# ...\n",
    "app = workflow.compile()\n",
    "```\n",
    "- Cria grafo de estado\n",
    "- Define nós e arestas\n",
    "- Compila o workflow para execução\n",
    "\n",
    "## Boas Práticas Observadas\n",
    "\n",
    "* **Tratamento de Erros**:\n",
    "  - Cada função possui try/catch\n",
    "  - Erros são armazenados no estado\n",
    "  - Permite rastreamento de problemas\n",
    "\n",
    "* **Modularidade**:\n",
    "  - Funções bem definidas com responsabilidade única\n",
    "  - Facilita manutenção e testes\n",
    "\n",
    "* **Tipagem**:\n",
    "  - Uso de TypedDict para garantir consistência\n",
    "  - Facilita detecção de erros em tempo de desenvolvimento\n",
    "\n",
    "## Sugestões de Melhorias\n",
    "\n",
    "* **Paralelização**:\n",
    "  - Algumas operações poderiam ser paralelizadas\n",
    "  - LangGraph suporta execução assíncrona\n",
    "\n",
    "* **Validação de Estado**:\n",
    "  - Adicionar validadores entre transições\n",
    "  - Garantir integridade dos dados\n",
    "\n",
    "* **Logging**:\n",
    "  - Implementar sistema de logging mais robusto\n",
    "  - Facilitar debug e monitoramento\n",
    "\n",
    "* **Testes**:\n",
    "  - Adicionar testes unitários para cada nó\n",
    "  - Testar fluxo completo com diferentes cenários\n",
    "\n",
    "Este código demonstra um uso prático e bem estruturado do LangGraph para criar um workflow de gerenciamento de inventário, seguindo boas práticas de programação e aproveitando os recursos da biblioteca.\n",
    "\n",
    "Considerações Finais\n",
    "Personalização:\n",
    "\n",
    "Você pode ajustar os parâmetros de previsão de demanda para utilizar modelos estatísticos mais avançados ou integrar com bibliotecas como statsmodels ou scikit-learn.\n",
    "Integre o sistema com APIs de fornecedores para automatizar os pedidos de reabastecimento.\n",
    "Segurança e Validação:\n",
    "\n",
    "Certifique-se de validar os dados de entrada e tratar exceções adequadamente para evitar falhas no sistema.\n",
    "Escalabilidade:\n",
    "\n",
    "Para sistemas maiores, considere o uso de bancos de dados mais robustos e a implementação de processamento assíncrono."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
